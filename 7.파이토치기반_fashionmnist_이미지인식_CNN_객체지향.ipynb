{"cells":[{"cell_type":"markdown","metadata":{"id":"Ks6D6EkVM-8l"},"source":["# 모듈가져오기"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":7073,"status":"ok","timestamp":1716170836180,"user":{"displayName":"shin ken","userId":"05680545463995967032"},"user_tz":-540},"id":"eK64yNLxNAdh"},"outputs":[],"source":["# 기본 토치\n","import torch\n","# 레이어 구성\n","import torch.nn as nn\n","# 함수들, 평가\n","import torch.nn.functional as F\n","# 최적화\n","import torch.optim as optim\n","\n","# 데이터 공급 -> 학습에 필요한 데이터 공급\n","from torchvision import transforms, datasets\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1716170836180,"user":{"displayName":"shin ken","userId":"05680545463995967032"},"user_tz":-540},"id":"NwwlGb5INHzK","outputId":"691417ff-40aa-4917-843f-80e75e40b008"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# GPU\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu' )\n","DEVICE"]},{"cell_type":"markdown","metadata":{"id":"u7cR-eKqOG5z"},"source":["# 데이터 준비 (수집, 준비, 전처리)"]},{"cell_type":"markdown","metadata":{"id":"JEFApeROOJmY"},"source":["- 훈련시 사용하는 데이터 공급은 공급자를 통해서 제공\n","- FashionMNIST\n","    - h, w = 28,28\n","    - 정답 10개"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1716170836180,"user":{"displayName":"shin ken","userId":"05680545463995967032"},"user_tz":-540},"id":"wyq47MdgOCdg"},"outputs":[],"source":["# 배치사이즈\n","BATCH_SIZE = 64 # 설정값"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5783,"status":"ok","timestamp":1716170841955,"user":{"displayName":"shin ken","userId":"05680545463995967032"},"user_tz":-540},"id":"d_JM809COc8y","outputId":"e3e9b7b6-375d-404f-8afd-b56e8ead2198"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 26421880/26421880 [00:01<00:00, 13367333.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 29515/29515 [00:00<00:00, 271706.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4422102/4422102 [00:00<00:00, 5036697.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5148/5148 [00:00<00:00, 20741860.70it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# 훈련 데이터 공급자\n","train_loader = DataLoader(\n","    dataset     = datasets.FashionMNIST(\n","        root    = './data',  # 다운로드될 위치, 데이터를 읽어오는 위치, 저장된 위치\n","        train   = True,      # 이 데이터는 훈련용임\n","        download= True,      # 데이터가 해당 경로에 없으면 다운로드\n","        transform   = transforms.Compose([\n","            # 이미지(데이터)에 대한 전처리\n","            transforms.ToTensor(), # 데이터를 공급할대 텐서로 제공하겠다\n","            transforms.Normalize( 0.2, 0.3 ) # 평균, 표준편차\n","        ]),\n","    ),  # 패션 이미지 데이터\n","    batch_size  = BATCH_SIZE,\n","    shuffle     = True\n",")"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1716170841955,"user":{"displayName":"shin ken","userId":"05680545463995967032"},"user_tz":-540},"id":"iSpeQ9SUOhVr"},"outputs":[],"source":["# 테스트 데이터 공급자\n","test_loader = DataLoader(\n","    dataset     = datasets.FashionMNIST(\n","        root    = './data',  # 다운로드될 위치, 데이터를 읽어오는 위치, 저장된 위치\n","        train   = False,      # 이 데이터는 테스트용임\n","        download= True,      # 데이터가 해당 경로에 없으면 다운로드\n","        transform   = transforms.Compose([\n","            # 이미지(데이터)에 대한 전처리\n","            transforms.ToTensor(), # 데이터를 공급할대 텐서로 제공하겠다\n","            transforms.Normalize( 0.2, 0.3 ) # 평균, 표준편차\n","        ]),\n","    ),  # 패션 이미지 데이터\n","    batch_size  = BATCH_SIZE,\n","    shuffle     = True\n",")"]},{"cell_type":"markdown","metadata":{"id":"VaYNgwoUQ34x"},"source":["# 인공신경망 구축- 객체 지향 스타일"]},{"cell_type":"markdown","metadata":{"id":"4kAAlqZZRBSm"},"source":["```\n","- 입력층\n","- 은닉층\n","    - 합성곱층 1f\n","    - 풀링층 1f\n","    - 합성곱층 2f :\n","    - 풀링층 2f :\n","    - flattern + 전결합층 :\n","    - 드롭아웃층\n","- 출력층\n","```"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1716170841955,"user":{"displayName":"shin ken","userId":"05680545463995967032"},"user_tz":-540},"id":"GFkicjCEQvAQ"},"outputs":[],"source":["class Net(nn.Module):\n","    # 생성자\n","    def __init__(self):\n","        '''\n","            - 중요한 각 층(layer)을 구성(맴버 변수)\n","        '''\n","        super(Net, self).__init__()\n","        # 맴버 변수로 만들지 않은 층은 => 함수로 처리하겠다 (설정)\n","        # 합성곱층 2개\n","        self.conv1      = nn.Conv2d(1,  32, 5, 1, padding='same') # 합성곱 1f\n","        self.conv2      = nn.Conv2d(32, 64, 5, 1, padding='same') # 합성곱 2f\n","        # 과적합 방지층\n","        self.dropout    = nn.Dropout2d(0.1) # 10% 훈련 방해 비율\n","        # 전결합층\n","        # shape 설계가 된후 작성 가능\n","        # 28 -> 14 -> 7 : flatter =>? 7*7*64\n","        self.fc         = nn.Linear( 7*7*64, 1024 ) # 1024 수렴\n","        # 출력층\n","        self.output     = nn.Linear( 1024, 10)      # 10 수렴\n","        pass\n","\n","    # 순전파신경망 - 인공신경망 구성 -\n","    # 함수 입력 => 입력층\n","    # 함수 출력 => 출력층\n","    def forward(self, x):\n","        # x : 입력층\n","        # 합성곱층(합성곱층, 풀링층) 이런식으로 묶어서 표현도 가능 -> feature map -> activation_map\n","        # 이미지 크기 28 -> 14\n","        # 객체를 함수처럼 사용 => 내부에 __call__() 구현되있다면 사용가능\n","        x = F.relu( F.max_pool2d( self.conv1(x), 2 )) # 1f (합성곱, 풀링) 완료\n","        # 2f, dropout을 부여한다면 (임의로 부여)\n","        # 이미지 크기 14 -> 7\n","        x = F.relu( F.max_pool2d( self.dropout(self.conv2(x)), 2 ))\n","        # 전결합층에 결합하기 위해 -> 사전에 flattern 처리(4D->2D)\n","        # x텐서 => 4D->2D 처리를 위해 view()로 처리\n","        x = x.view( -1, 64*7*7) # 데이터 1개당(이미지 1개당) => 7*7의 데이터가 64개 준비되어 있음\n","        # 전결합층\n","        x = self.dropout( F.relu( self.fc(x) ) )\n","        # 출력층\n","        # F.softmax() => 데이터를 원본 그대로 사용한다면 주로 사용\n","        # F.log_softmax() => 데이터가 정규화등으로 조정된다면 -> 분포 변경이 될경우 주로 사용\n","        return F.log_softmax( self.output( x ), dim=1) # 개별 옷에 대한 확률값"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":762,"status":"ok","timestamp":1716170842716,"user":{"displayName":"shin ken","userId":"05680545463995967032"},"user_tz":-540},"id":"Xoj3ul1IR_K0","outputId":"2ee3e8de-7135-4d31-f578-48718c2182b0"},"outputs":[{"data":{"text/plain":["Net(\n","  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=same)\n","  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=same)\n","  (dropout): Dropout2d(p=0.1, inplace=False)\n","  (fc): Linear(in_features=3136, out_features=1024, bias=True)\n","  (output): Linear(in_features=1024, out_features=10, bias=True)\n",")"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["model = Net().to(DEVICE) # cpu|cuda를 설정\n","model"]},{"cell_type":"markdown","metadata":{"id":"QD1BXCX5ZTEH"},"source":["# 학습에 대한 도구 세팅"]},{"cell_type":"markdown","metadata":{"id":"WFycYrHqZceL"},"source":["- 케리스\n","    - 컴파일 옵션\n","        - 최적화도구, 손실함수, 평가지표\n","- 토치\n","    - 대동 소이함\n","        - 최적화도구 설정\n","        - 손실, 평가지표등(정확도)등은 실제 학습시 처리하는것으로 조정"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1716170842716,"user":{"displayName":"shin ken","userId":"05680545463995967032"},"user_tz":-540},"id":"XYVgQMGwaTfC","outputId":"f90a2a6c-8864-4544-ca0a-6dde0c67caef"},"outputs":[{"data":{"text/plain":["<generator object Module.parameters at 0x7e3f93794cf0>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["model.parameters() # 학습을 통해서 최적화 해야할 가중치, 편향등"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1716170842716,"user":{"displayName":"shin ken","userId":"05680545463995967032"},"user_tz":-540},"id":"oOo2FqKjRt34"},"outputs":[],"source":["# 최적화 도구\n","# 최적화 대상, 학습률, 가속도\n","opimzer = optim.SGD( model.parameters(), lr=0.01, momentum=0.5)"]},{"cell_type":"markdown","metadata":{"id":"35ZLfyYobJqY"},"source":["# 훈련( 학습 )"]},{"cell_type":"markdown","metadata":{"id":"Svsfyu8zbRG2"},"source":["## 훈련용 함수"]},{"cell_type":"markdown","metadata":{"id":"RrybXlrTjysV"},"source":["- 크로스엔트로피\n","    - 두 확률 분포 간의 차이를 측정하는 메트릭\n","    - 실제값, 예측값 사이의 차이 => 손실함수"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1716170842717,"user":{"displayName":"shin ken","userId":"05680545463995967032"},"user_tz":-540},"id":"hncJsqx5bZfk"},"outputs":[],"source":["def train( model, train_loader, opimzer, epoch, verbose=True):\n","    '''\n","        모델 학습 함수\n","        - model : 훈련시킬 모델\n","        - train_loader : 훈련용 데이터 공급용 공급자\n","        - opimzer : 모델의 파라미터를 최적화할 도구\n","        - epoch : 학습 세대 값\n","    '''\n","    # 1. 모델을 학습 모드로 전환\n","    model.train()\n","    # 2. 미니 배치(컨셉) 학습\n","    for idx, (data, target) in enumerate( train_loader ): # 학습순번,피처데이터, 정답데이터\n","        # 2-1. cpu or cuda 설정\n","        data, target = data.to(DEVICE), target.to(DEVICE)\n","        # 2-2. 최적화 도구 초기화 진행. 학습이 진행되면 도구가 조정이 된다 => 다음번 학습시 영향을 미침, 0으로 조정\n","        opimzer.zero_grad()\n","        # 2-3. 데이터를 모델에 주입 -> 출력층 (개별 옷에 대한 확률) : 순전파\n","        output = model( data )\n","        # 2-4. 실제값과 예측값 사이 차이 계산 => 크로스엔트로피 함수를 활용 => loss\n","        loss = F.cross_entropy( output, target )\n","        # 2-5. 오차역전파 진행 (y->x 이동하면서 가중치 업데이트) => 최적화 행위 => 가중치들은 기록\n","        loss.backward()\n","        # 2-6. 최적화된 파라미터를 모델에 반영 => 학습 행위 1회 종료\n","        opimzer.step()\n","        # 2-7. 로그 출력(필요시, 필요한 타이밍에 맞춰)\n","        if verbose and idx % 200 == 0:  # 200단위로 로그 출력\n","            # loss => 텐서 => 차원표시가 나옴[ [] ]<= 이런 표시를 제외한 실제값 출력 item()\n","            print( f'Epoch:{epoch}\\t mini-batch:{idx}\\t loss:{loss.item()}' )\n","\n","        pass\n","    # 3. 체크 포인트 저장 -> 모델 덤프 (*.pt or *.pth)\n","    # 세대별 학습이 마무리되면 저장, 이전 모델보다 성능이 향상되면 저장(컨셉을 부여, 추가 구현)\n","    torch.save({\n","        'model'                 : 'train-model',\n","        'epoch'                 : epoch,\n","        'model_state_dict'      : model.state_dict(),\n","        'opimzer_state_dict'    : opimzer.state_dict(),\n","        # 필요시 추가 정보\n","        'desc'                  : f'train-model checkpoint-{epoch}'\n","    }, f'./model-checkpoint-{epoch}.pt')\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"Q9-Un7_LbRJ5"},"source":["## 테스트용 함수"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1716170842717,"user":{"displayName":"shin ken","userId":"05680545463995967032"},"user_tz":-540},"id":"tUnJCdZ9bmuA"},"outputs":[],"source":["def test( model, test_loader ):\n","    '''\n","        세대별(epoch) 학습결과를 기반 -> 모델을 이용하여 테스트 진행 -> 평균 손실, 정확도 점검\n","        - model : 현재까지 학습된 모델\n","        - test_loader : 테스트 데이터 공급용 공급자\n","    '''\n","    # 1. 테스트 결과를 담을 변수 초기화\n","    mean_loss, mean_acc = (0,0)\n","    # 2. 모델을 테스트 모드로 전환\n","    model.eval()\n","    # 3. 테스트 진행한 모든 내용은 기록하지 않는다 세팅 -> 모델 성능에 영향 X\n","    with torch.no_grad(): # 이후 진행되는 행위에 대한 계산, 기록 X, 테스트 데이터 모두 사용->테스트완료\n","        # 3-1 테스트 데이터 공급 테스트 진행\n","        for idx, (data, target) in enumerate( test_loader ):\n","            # 3-1-1 cpu or cuda 설정\n","            data, target = data.to(DEVICE), target.to(DEVICE)\n","            # 3-1-2 모델에 데이터 주입\n","            output = model( data )\n","            # 3-1-3 실제값, 예측값 차이를 계산 => 손실함수 => 누적해서 합산 => mean_loss\n","            # 데이터 64개에 대한 오차값 => 합산 => .... => 모든데이터에 대한 오차값 합산\n","            mean_loss += F.cross_entropy( output, target, reduction='sum' ).item()\n","            # 3-1-4 정확도 계산(텐서 연산) => 누적합산 => mean_acc\n","            # 출력층(텐서) -> 각 10개의 옷의 확률값 보관(...softmax)-> 대상 텐서들중에서 가장 높은값을가진 텐서의 인덱스 정보 획득\n","            # output => 2D, (데이터의수, 10)\n","            y_pred = output.max(1, keepdim=True)[1]\n","            # 실제값(0,1,..,9), 위에서 추출한 인덱스정보(0,1, .. 9) => eq() => sum() => item() => 누적합\n","            # shape 맞춰주는 함수 : 원본.view_as(바꾸고싶은대상) => 차원값을 모두 곱한값이 동일해야함\n","            # 64개 데이터중에 원본과 일치하는 개수 획득\n","            mean_acc += y_pred.eq( target.view_as(y_pred) ).sum().item()\n","            # 맞춘개수를 계소 누적합\n","\n","    # 4. mean_loss, mean_acc(맞춘개수/전체개수*100) 계산\n","    mean_loss = mean_loss / len(test_loader.dataset)\n","    mean_acc  = mean_acc / len(test_loader.dataset) * 100 # 퍼센트 단위환산\n","\n","    # 5. mean_loss, mean_acc 반환\n","    return mean_loss, mean_acc"]},{"cell_type":"markdown","metadata":{"id":"AJ54RfhrwA81"},"source":["- 특정 모듈 단위 테스트"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1716170842717,"user":{"displayName":"shin ken","userId":"05680545463995967032"},"user_tz":-540},"id":"M25z_4JYpx_c","outputId":"59b07fbb-55f1-4124-f9cd-045988954814"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1., 1., 2., 0.]) tensor([0., 0., 1., 1.])\n","tensor(3.2530)\n","3.253046989440918\n"]}],"source":["a = torch.Tensor( [1, 1, 2, 0 ] )\n","b = torch.Tensor( [0, 0, 1, 1 ] )\n","print( a, b )\n","\n","print( F.cross_entropy( a, b) ) # 결과값을 평균내여서 리턴 기본값, mean\n","print( F.cross_entropy( a, b, reduction='sum' ).item() ) # 평균 X, 합산으로 기록"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1716170842717,"user":{"displayName":"shin ken","userId":"05680545463995967032"},"user_tz":-540},"id":"n3SgicV7rZuI","outputId":"460bf5ac-5edd-49de-dbd8-4ca72f397178"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0,  1,  2,  3],\n","        [ 4,  5,  6,  7],\n","        [ 8,  9, 10, 11],\n","        [12, 13, 14, 15]])\n","tensor(15)\n","torch.return_types.max(\n","values=tensor([ 3,  7, 11, 15]),\n","indices=tensor([3, 3, 3, 3]))\n","tensor([3, 3, 3, 3])\n","tensor([[3],\n","        [3],\n","        [3],\n","        [3]])\n"]}],"source":["tenser = torch.arange(16).view(4,4)\n","'''\n","tensor([[ 0,  1,  2,  3],  <- 샘플 데이터 1\n","        [ 4,  5,  6,  7],  <- 샘플 데이터 2\n","        [ 8,  9, 10, 11],  <- 샘플 데이터 3\n","        [12, 13, 14, 15]]) <- 샘플 데이터 4 라고 가정하면 이해하기 쉬움\n","'''\n","# 원본\n","print( tenser )\n","# 원본 테서들중 가장 큰값\n","print( tenser.max() )\n","# 텐서의 1=> 두번재차원, 차원번호 1번에 최대값추출 => [값, 인덱스]\n","print( tenser.max(1) )\n","# 텐서의 1=> 두번재차원, 차원번호 1번에 최대값추출 => 인덱스만 추출\n","print( tenser.max(1)[1] )\n","# 차원을 유지하면서 최대값을 가진 인덱스만 추출\n","print( tenser.max(1, keepdim=True)[1] )"]},{"cell_type":"markdown","metadata":{"id":"VgV9xIe0bRMn"},"source":["## 훈련 진행"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":175699,"status":"ok","timestamp":1716171018414,"user":{"displayName":"shin ken","userId":"05680545463995967032"},"user_tz":-540},"id":"T2DHEPxDa7o8","outputId":"eced71a8-4ea2-44ec-a882-68026fddf751"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1347: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n","  warnings.warn(warn_msg)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch:1\t mini-batch:0\t loss:2.302290201187134\n","Epoch:1\t mini-batch:200\t loss:0.6654482483863831\n","Epoch:1\t mini-batch:400\t loss:0.583935022354126\n","Epoch:1\t mini-batch:600\t loss:0.6952916383743286\n","Epoch:1\t mini-batch:800\t loss:0.3591659963130951\n","epoch:1\t loss=0.4454143620491028\t acc=83.91\n","Epoch:2\t mini-batch:0\t loss:0.4541183114051819\n","Epoch:2\t mini-batch:200\t loss:0.23918388783931732\n","Epoch:2\t mini-batch:400\t loss:0.23563280701637268\n","Epoch:2\t mini-batch:600\t loss:0.5074765682220459\n","Epoch:2\t mini-batch:800\t loss:0.42524269223213196\n","epoch:2\t loss=0.3861288519382477\t acc=86.1\n","Epoch:3\t mini-batch:0\t loss:0.2548559308052063\n","Epoch:3\t mini-batch:200\t loss:0.26245588064193726\n","Epoch:3\t mini-batch:400\t loss:0.30270087718963623\n","Epoch:3\t mini-batch:600\t loss:0.48542168736457825\n","Epoch:3\t mini-batch:800\t loss:0.42018911242485046\n","epoch:3\t loss=0.3342477601051331\t acc=87.71\n","Epoch:4\t mini-batch:0\t loss:0.2687333822250366\n","Epoch:4\t mini-batch:200\t loss:0.2867429852485657\n","Epoch:4\t mini-batch:400\t loss:0.4518964886665344\n","Epoch:4\t mini-batch:600\t loss:0.3861672878265381\n","Epoch:4\t mini-batch:800\t loss:0.2828339636325836\n","epoch:4\t loss=0.3165507873535156\t acc=88.44\n","Epoch:5\t mini-batch:0\t loss:0.23458248376846313\n","Epoch:5\t mini-batch:200\t loss:0.3285555839538574\n","Epoch:5\t mini-batch:400\t loss:0.2153427004814148\n","Epoch:5\t mini-batch:600\t loss:0.3235850930213928\n","Epoch:5\t mini-batch:800\t loss:0.28142085671424866\n","epoch:5\t loss=0.2940669124603271\t acc=89.56\n","Epoch:6\t mini-batch:0\t loss:0.3880862593650818\n","Epoch:6\t mini-batch:200\t loss:0.44228869676589966\n","Epoch:6\t mini-batch:400\t loss:0.2336610108613968\n","Epoch:6\t mini-batch:600\t loss:0.2408275306224823\n","Epoch:6\t mini-batch:800\t loss:0.29516157507896423\n","epoch:6\t loss=0.289024803686142\t acc=89.73\n","Epoch:7\t mini-batch:0\t loss:0.24730345606803894\n","Epoch:7\t mini-batch:200\t loss:0.19419288635253906\n","Epoch:7\t mini-batch:400\t loss:0.2669709026813507\n","Epoch:7\t mini-batch:600\t loss:0.2729193866252899\n","Epoch:7\t mini-batch:800\t loss:0.22997157275676727\n","epoch:7\t loss=0.283906627869606\t acc=89.47\n","Epoch:8\t mini-batch:0\t loss:0.2727639377117157\n","Epoch:8\t mini-batch:200\t loss:0.25673091411590576\n","Epoch:8\t mini-batch:400\t loss:0.37795642018318176\n","Epoch:8\t mini-batch:600\t loss:0.2301468849182129\n","Epoch:8\t mini-batch:800\t loss:0.14329376816749573\n","epoch:8\t loss=0.25476895473003386\t acc=90.63\n","Epoch:9\t mini-batch:0\t loss:0.23502886295318604\n","Epoch:9\t mini-batch:200\t loss:0.2794063687324524\n","Epoch:9\t mini-batch:400\t loss:0.28047341108322144\n","Epoch:9\t mini-batch:600\t loss:0.21088755130767822\n","Epoch:9\t mini-batch:800\t loss:0.24134117364883423\n","epoch:9\t loss=0.25680886676311493\t acc=90.53\n","Epoch:10\t mini-batch:0\t loss:0.20536118745803833\n","Epoch:10\t mini-batch:200\t loss:0.24949373304843903\n","Epoch:10\t mini-batch:400\t loss:0.26967161893844604\n","Epoch:10\t mini-batch:600\t loss:0.16213415563106537\n","Epoch:10\t mini-batch:800\t loss:0.24010081589221954\n","epoch:10\t loss=0.25058667533397677\t acc=91.21000000000001\n"]}],"source":["%%time\n","EPOCHS = 10\n","# 학습 성과에 대한 시각화\n","losses, accs = list(), list()\n","for epoch in range( 1, EPOCHS+1):\n","    # 훈련\n","    train( model, train_loader, opimzer, epoch)\n","    # 테스트\n","    mean_loss, mean_acc = test( model, test_loader)\n","    losses.append( mean_loss)\n","    accs.append(   mean_acc)\n","    # 로그 출력\n","    print( f'epoch:{epoch}\\t loss={mean_loss}\\t acc={mean_acc}' )"]},{"cell_type":"markdown","metadata":{"id":"I1I09ikpw898"},"source":["# 학습 결과 정리"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1716171119145,"user":{"displayName":"shin ken","userId":"05680545463995967032"},"user_tz":-540},"id":"KBAhBXuAdSQd","outputId":"1bfeffee-6aa5-4a81-d72e-4b11a6ddb8dc"},"outputs":[{"data":{"text/plain":["([0.4454143620491028,\n","  0.3861288519382477,\n","  0.3342477601051331,\n","  0.3165507873535156,\n","  0.2940669124603271,\n","  0.289024803686142,\n","  0.283906627869606,\n","  0.25476895473003386,\n","  0.25680886676311493,\n","  0.25058667533397677],\n"," [83.91,\n","  86.1,\n","  87.71,\n","  88.44,\n","  89.56,\n","  89.73,\n","  89.47,\n","  90.63,\n","  90.53,\n","  91.21000000000001])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# 아래 데이터를 기반으로 시각화 가능 => QnA\n","losses, accs"]},{"cell_type":"markdown","metadata":{"id":"hzRxaJonw_vg"},"source":["- cuda 기반 학습 진행\n","    - 10 epoch 기준\n","        - loss=0.25058667533397677\n","        - acc=91.21000000000001\n","    - 추가 학습 더 필요 (학습 횟수가 적음)\n","        - 모델 성능이 지속적으로 향상됨이 보임\n","        - 필요시 조기 학습 종료 추가"]},{"cell_type":"markdown","metadata":{"id":"VyQXwn3Bxttp"},"source":["# 모델 덤플 및 로드"]},{"cell_type":"markdown","metadata":{"id":"gituAedGzBsP"},"source":["- 기본 모델만 저장"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":245,"status":"ok","timestamp":1716171280651,"user":{"displayName":"shin ken","userId":"05680545463995967032"},"user_tz":-540},"id":"VeV3z3zuxRfS"},"outputs":[],"source":["# 최종 모델 저장\n","torch.save( model, 'model.pt' )"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":405,"status":"ok","timestamp":1716171337574,"user":{"displayName":"shin ken","userId":"05680545463995967032"},"user_tz":-540},"id":"jzHQ_6VMx41U"},"outputs":[],"source":["# 로드\n","# map_location : cpu or cuda 설정 맞춤\n","model2 = torch.load( 'model.pt', map_location=DEVICE)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":330,"status":"ok","timestamp":1716171511143,"user":{"displayName":"shin ken","userId":"05680545463995967032"},"user_tz":-540},"id":"BrxxrhPyyGsI","outputId":"b3f5b082-e92e-4c39-859a-0e612b99fd07"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.23934680223464966 93.75\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1347: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n","  warnings.warn(warn_msg)\n"]}],"source":["# 테스트\n","loss, acc = (0,0)\n","model2.eval()\n","with torch.no_grad():\n","    for idx, (data, target) in enumerate( test_loader ):\n","        data, target    = data.to(DEVICE), target.to(DEVICE)\n","        output          = model( data )\n","        loss           += F.cross_entropy( output, target, reduction='sum' ).item()\n","        y_pred          = output.max(1, keepdim=True)[1]\n","        acc            += y_pred.eq( target.view_as(y_pred) ).sum().item()\n","        # 1회만 진행\n","        print( loss/BATCH_SIZE, acc/BATCH_SIZE*100)\n","        break"]},{"cell_type":"markdown","metadata":{"id":"BarPcODAy_Xe"},"source":["- model.state_dict() 사용"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":265,"status":"ok","timestamp":1716171624387,"user":{"displayName":"shin ken","userId":"05680545463995967032"},"user_tz":-540},"id":"E45Utje5yxGW"},"outputs":[],"source":["# 모델 상태 저장 하기\n","torch.save( model.state_dict(), 'model_state_dict.pt')"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":356,"status":"ok","timestamp":1716171691860,"user":{"displayName":"shin ken","userId":"05680545463995967032"},"user_tz":-540},"id":"0isC4o-BzMw6","outputId":"30a2cf39-9e59-4147-eab2-8b70a914350d"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# 상태 로드\n","state = torch.load( 'model_state_dict.pt', map_location=DEVICE)\n","# 기존 모델에 교체(설정)\n","model2.load_state_dict( state )"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":253,"status":"ok","timestamp":1716171710213,"user":{"displayName":"shin ken","userId":"05680545463995967032"},"user_tz":-540},"id":"L1a7x-z9zdNg","outputId":"3bdb4f54-2aaf-46fd-8781-764aba280714"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.15921537578105927 93.75\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1347: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n","  warnings.warn(warn_msg)\n"]}],"source":["loss, acc = (0,0)\n","model2.eval()\n","with torch.no_grad():\n","    for idx, (data, target) in enumerate( test_loader ):\n","        data, target    = data.to(DEVICE), target.to(DEVICE)\n","        output          = model( data )\n","        loss           += F.cross_entropy( output, target, reduction='sum' ).item()\n","        y_pred          = output.max(1, keepdim=True)[1]\n","        acc            += y_pred.eq( target.view_as(y_pred) ).sum().item()\n","        # 1회만 진행\n","        print( loss/BATCH_SIZE, acc/BATCH_SIZE*100)\n","        break\n","\n","# 공급데이터가 변경되어서 손실값, 정확도가 상이해짐"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nnNYXrQVzhow"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMdoOBSRXLj3UHEYm5WIAQI","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
